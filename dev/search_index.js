var documenterSearchIndex = {"docs":
[{"location":"man/model-specification/#user-guide-model-specification","page":"Model Specification","title":"Model Specification","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Probabilistic models incorporate elements of randomness to describe an event or phenomenon by using random variables and probability theory. A probabilistic model can be represented visually by using probabilistic graphical models (PGMs). A factor graph is a type of PGM that is well suited to cast inference tasks in terms of graphical manipulations.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"GraphPPL.jl is a Julia package presenting a model specification language for probabilistic models.","category":"page"},{"location":"man/model-specification/#@model-macro","page":"Model Specification","title":"@model macro","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"The ReactiveMP uses GraphPPL library to simplify model specification. It is not necessary but highly recommended to use ReactiveMP in a combination with GraphPPL model specification library. The GraphPPL library exports a single @model macro for model specification. The @model macro accepts two arguments: model options (optionally) and the model specification itself in a form of regular Julia function. ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"For example: ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"# `@model` macro accepts an array of named options as a first argument and\n# a regular Julia function body as its second argument\n@model [ option1 = ..., option2 = ... ] function model_name(model_arguments...)\n    # model specification goes here\n    return ...\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Model options are optional and may be omitted:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"@model function model_name(model_arguments...)\n    # model specification here\n    return ...\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"that is equivalent to ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"# Empty options if ommited\n@model [] function model_name(model_arguments...)\n    # model specification here\n    return ...\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"The @model macro returns a regular Julia function (in this example model_name(model_arguments...)) that has the same signature and can be executed as usual. It returns a reference to a model object itself and a tuple of a user specified return variables, e.g:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"@model function my_model(model_arguments...)\n    # model specification here\n    # ...\n    return x, y\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"model, (x, y) = my_model(model_arguments...)","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"It is also important to note that any model should return something, such as variables or nodes. If a model doesn't return anything then an error will be raised during runtime.  model object might be useful to inspect model's factor graph and/or factor nodes and variables. It is also used in Bethe Free Energy score computation. If not needed it can be ommited with _ placeholder, eg:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"_, (x, y) = my_model(model_arguments...)","category":"page"},{"location":"man/model-specification/#A-full-example-before-diving-in","page":"Model Specification","title":"A full example before diving in","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Before presenting the details of the model specification syntax, we show an example of a simple probabilistic model. Here we create a linear gaussian state space model with latent random variables x and noisy observations y:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"@model [ options... ] function state_space_model(n_observations, noise_variance)\n\n    x = randomvar(n_observations)\n    y = datavar(Float64, n_observations)\n\n    x[1] ~ NormalMeanVariance(0.0, 100.0)\n\n    for i in 2:n_observations\n       x[i] ~ x[i - 1] + 1.0\n       y[i] ~ NormalMeanVariance(x[i], noise_variance)\n    end\n\n    return x, y\nend","category":"page"},{"location":"man/model-specification/#Model-variables","page":"Model Specification","title":"Model variables","text":"","category":"section"},{"location":"man/model-specification/#Constants","page":"Model Specification","title":"Constants","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Any runtime constant passed to a model as a model argument will be automatically converted to a fixed constant in the graph model. This convertion happens every time when model specification identifies a constant. Sometimes it might be useful to create constants by hand (e.g. to avoid copying large matrices across the model and to avoid extensive memory allocations).","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"You can create a constant within a model specification macro with constvar() function. For example:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"c = constvar(1.0)\n\nfor i in 2:n\n    x[i] ~ x[i - 1] + c # Reuse the same reference to a constant 1.0\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Additionally you can specify an extra ::ConstVariable type for some of the model arguments. In this case macro automatically converts them to a single constant using constvar() function. E.g.:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"@model function model_name(nsamples::Int, c::ConstVariable)\n    # ...\n    # no need to call for a constvar() here\n    for i in 2:n\n        x[i] ~ x[i - 1] + c # Reuse the same reference to a constant `c`\n    end\n    # ...\n    return ...\nend","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"note: Note\n::ConstVariable does not restrict an input type of an argument and does not interfere with multiple dispatch. In this example c can have any type, e.g. Int.","category":"page"},{"location":"man/model-specification/#Data-variables","page":"Model Specification","title":"Data variables","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"It is important to have a mechanism to pass data values to the model. You can create data inputs with datavar() function. As a first argument it accepts a type specification and optional dimensionality (as additional arguments or as a tuple).","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Examples: ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y = datavar(Float64) # Creates a single data input with `y` as identificator\ny = datavar(Float64, n) # Returns a vector of  `y_i` data input objects with length `n`\ny = datavar(Float64, n, m) # Returns a matrix of `y_i_j` data input objects with size `(n, m)`\ny = datavar(Float64, (n, m)) # It is also possible to use a tuple for dimensionality, it is an equivalent of the previous line","category":"page"},{"location":"man/model-specification/#Random-variables","page":"Model Specification","title":"Random variables","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"There are several ways to create random variables. The first one is an explicit call to randomvar() function. By default it doesn't accept any argument, creates a single random variable in the model and returns it. It is also possible to pass dimensionality arguments to randomvar() function in the same way as for the datavar() function.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Examples: ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"x = randomvar() # Returns a single random variable which can be used later in the model\nx = randomvar(n) # Returns an vector of random variables with length `n`\nx = randomvar(n, m) # Returns a matrix of random variables with size `(n, m)`\nx = randomvar((n, m)) # It is also possible to use a tuple for dimensionality, it is an equivalent of the previous line","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"The second way to create a random variable is to use the ~ operator. If the random variable hasn't been created yet, ~ operator will be creat it automatically during the creation of the node. Read more about the ~ operator in the next section.","category":"page"},{"location":"man/model-specification/#Factor-nodes","page":"Model Specification","title":"Factor nodes","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Factor nodes (or local functions) are used to define a relationship between random variables and/or constants and data inputs. In most of the cases a factor node defines a probability distribution over selected random variables. ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"We model a random variable by a probability distribution using the ~ operator. For example, to create a random variable y which is modeled by a Normal distribution, where its mean and variance are controlled by the random variables m and v respectively, we define","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"m = randomvar()\nv = randomvar()\ny ~ NormalMeanVariance(m, v) # Creates a `y` random variable automatically","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"It is also possible to use a deterministic relationships between random variables:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"a = randomvar()\nb = randomvar()\nc ~ a + b # Here with the help of `~` operator we explictly say that `c` is a random variable too","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"note: Note\nThe GraphPPL.jl package uses the ~ operator for modelling both stochastic and deterministic relationships between random variables.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"The @model macro automatically resolves any inner function calls into anonymous extra nodes. It is also worth to note that inference backend will try to optimize inner deterministic function calls in the case where all arguments are constants or data inputs. For example:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"noise ~ NormalMeanVariance(mean, inv(precision)) # Will create a non-linear node `inv` in case if `precision` is a random variable. Won't create an additional non-linear node in case if `precision` is a constant or data input.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"It is possible to use any functional expression within the ~ operator arguments list. The only one exception is the ref expression (e.g x[i] or x[i, j]). In principle x[i] expression is equivalent to getindex(x, i) and therefore might be treated as a factor node with getindex as local function, however all ref expressions within the ~ operator arguments list are left untouched during model parsing. This means that the model parser will not create unnecessary nodes when only simple indexing is involved.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y ~ NormalMeanVariance(x[i - 1], variance) # While in principle `x[i - 1]` is equivalent to (`getindex(x, -(i, 1))`) model parser will leave it untouched and won't create any anonymous nodes for this expression.\n\ny ~ NormalMeanVariance(A * x[i - 1], variance) # This example will create a `*` anonymous node (in case if x[i - 1] is a random variable) and leave `x[i - 1]` untouched.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"It is also possible to return a node reference from the ~ operator with the following syntax:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"node, y ~ NormalMeanVariance(mean, var)","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Having a node reference can be useful in case the user wants to return it from a model and to use it later on to specify initial joint marginal distributions.","category":"page"},{"location":"man/model-specification/#Node-creation-options","page":"Model Specification","title":"Node creation options","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"To pass optional arguments to the node creation constructor the user can use the where { options...  } specification syntax.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Example:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean)q(y_var)q(y) } # mean-field factorisation over q","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"A list of all available options is presented below:","category":"page"},{"location":"man/model-specification/#Factorisation-constraint-option","page":"Model Specification","title":"Factorisation constraint option","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Users can specify a factorisation constraint over the approximate posterior q for variational inference. The general syntax for factorisation constraints over q is the following:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"variable ~ Node(node_arguments...) where { q = RecognitionFactorisationConstraint }","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"where RecognitionFactorisationConstraint can be one the following:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"MeanField()","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Automatically specifies a mean-field factorisation","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Example:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = MeanField() }","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"FullFactorisation()","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Automatically specifies a full factorisation (this is the default)","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Example:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = FullFactorisation() }","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"q(μ)q(v)q(out) or q(μ) * q(v) * q(out)","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"A user can specify any factorisation he wants as the multiplication of q(interface_names...) factors. As interface names the user can use the interface names of an actual node (read node's documentation), its aliases (if available) or actual random variable names present in the ~ operator expression.","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Examples: ","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"# Using interface names of a `NormalMeanVariance` node for factorisation constraint. \n# Call `?NormalMeanVariance` to know more about interface names for some node\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ)q(v)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ, v)q(out) }\n\n# Using interface names aliases of a `NormalMeanVariance` node for factorisation constraint. \n# Call `?NormalMeanVariance` to know more about interface names aliases for some node\n# In general aliases correspond to the function names for distribution parameters\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(mean)q(var)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(mean, var)q(out) }\n\n# Using random variables names from `~` operator expression\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean)q(y_var)q(y) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean, y_var)q(y) }\n\n# All methods can be combined easily\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ)q(y_var)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean, v)q(y) }","category":"page"},{"location":"man/model-specification/#Metadata-option","page":"Model Specification","title":"Metadata option","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"Is is possible to pass any extra metadata to a factor node with the meta option (if node supports it, read node's documentation). Metadata can be later accessed in message computation rules:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"z ~ f(x, y) where { meta = ... }","category":"page"},{"location":"man/model-specification/#Pipeline-option","page":"Model Specification","title":"Pipeline option","text":"","category":"section"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"To assign a factor node's local pipeline we use a pipeline option:","category":"page"},{"location":"man/model-specification/","page":"Model Specification","title":"Model Specification","text":"y ~ NormalMeanVariance(m, v) where { pipeline = LoggerPipelineStage() } # Logs all outbound messages with `LoggerPipelineStage`","category":"page"},{"location":"lib/message/#lib-message","page":"Messages","title":"Messages implementation","text":"","category":"section"},{"location":"lib/message/","page":"Messages","title":"Messages","text":"In message passing framework one of the most important concept is (wow!) messages. Messages flow on edges of a factor graph and usually hold some information in a form of probability distribution. In ReactiveMP.jl we distinguish two major types of messages: Belief Propagation and Variational.  ","category":"page"},{"location":"lib/message/#Abstract-message-type","page":"Messages","title":"Abstract message type","text":"","category":"section"},{"location":"lib/message/","page":"Messages","title":"Messages","text":"Both belief propagation and variational messages are subtypes of a AbstractMessage supertype.","category":"page"},{"location":"lib/message/","page":"Messages","title":"Messages","text":"AbstractMessage","category":"page"},{"location":"lib/message/#Belief-propagation-message","page":"Messages","title":"Belief propagation message","text":"","category":"section"},{"location":"lib/message/","page":"Messages","title":"Messages","text":"(Image: message)","category":"page"},{"location":"lib/message/","page":"Messages","title":"Messages","text":"Message","category":"page"},{"location":"lib/message/#ReactiveMP.Message","page":"Messages","title":"ReactiveMP.Message","text":"Message{D} <: AbstractMessage\n\nMessage structure encodes a Belief Propagation message, which holds some data that usually a probability distribution, but can also be an arbitrary object. Message acts as a proxy structure to data object and proxies most of the statistical functions, e.g. mean, mode, cov etc.\n\nArguments\n\ndata::D: message always holds some data object associated with it\nis_clamped::Bool, specifies if this message is clamped\nis_initial::Bool, specifies if this message is initial\n\nExample\n\njulia> distribution = Gamma(10.0, 2.0)\nGamma{Float64}(α=10.0, θ=2.0)\n\njulia> message = Message(distribution, false, true)\nMessage(Gamma{Float64}(α=10.0, θ=2.0))\n\njulia> mean(message) \n20.0\n\njulia> getdata(message)\nGamma{Float64}(α=10.0, θ=2.0)\n\njulia> is_clamped(message)\nfalse\n\njulia> is_initial(message)\ntrue\n\n\nSee also: AbstractMessage\n\n\n\n\n\n","category":"type"},{"location":"man/getting-started/#user-guide-getting-started","page":"Getting Started","title":"Getting started","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"ReactiveMP.jl is a Julia package for Bayesian Inference on Factor Graphs by Message Passing. It supports both exact and variational inference algorithms.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"ReactiveMP package is a successor of the ForneyLab package. It follows the same ideas and concepts for message-passing based inference, but uses new reactive and efficient message passing implementation under the hood. The API between two packages is different due to a better flexibility, performance and new reactive approach for solving inference problems.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"This page provides the necessary information you need to get started with ReactiveMP. We will show the general approach to solving inference problems with ReactiveMP by means of a running example: inferring the bias of a coin.","category":"page"},{"location":"man/getting-started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Install ReactiveMP through the Julia package manager:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"] add ReactiveMP","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"note: Note\nFor best user experience you also need to install GraphPPL, Rocket and Distributions packages.","category":"page"},{"location":"man/getting-started/#Example:-Inferring-the-bias-of-a-coin","page":"Getting Started","title":"Example: Inferring the bias of a coin","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"The ReactiveMP approach to solving inference problems consists of three phases:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Model specification: ReactiveMP uses GraphPPL package for model specification part. It offers a domain-specific language to specify your probabilistic model.\nInference specification: ReactiveMP inference API has been designed to be as flexible as possible and it is compatible both with asynchronous infinite data streams and with static datasets. For most of the use cases it consists of the same simple building blocks. In this example we will show one of the many possible ways to infer your quantities of interest.\nInference execution: Given model specification and inference procedure it is pretty straightforward to use reactive API from Rocket to pass data to the inference backend and to run actual inference.","category":"page"},{"location":"man/getting-started/#Coin-flip-simulation","page":"Getting Started","title":"Coin flip simulation","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Let's start by creating some dataset. One approach could be flipping a coin N times and recording each outcome. For simplicity in this example we will use static pre-generated dataset. Each sample can be thought of as the outcome of single flip which is either heads or tails (1 or 0). We will assume that our virtual coin is biased, and lands heads up on 75% of the trials (on average).","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"First lets setup our environment by importing all needed packages:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"using Rocket, GraphPPL, ReactiveMP, Distributions, Random","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Next, lets define our dataset:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"rng = MersenneTwister(42)\nn = 10\np = 0.75\ndistribution = Bernoulli(p)\n\ndataset = float.(rand(rng, Bernoulli(p), n))","category":"page"},{"location":"man/getting-started/#Model-specification","page":"Getting Started","title":"Model specification","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"In a Bayesian setting, the next step is to specify our probabilistic model. This amounts to specifying the joint probability of the random variables of the system.","category":"page"},{"location":"man/getting-started/#Likelihood","page":"Getting Started","title":"Likelihood","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"We will assume that the outcome of each coin flip is governed by the Bernoulli distribution, i.e.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"y_i sim mathrmBernoulli(theta)","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"where y_i = 1 represents \"heads\", y_i = 0 represents \"tails\". The underlying probability of the coin landing heads up for a single coin flip is theta in 01.","category":"page"},{"location":"man/getting-started/#Prior","page":"Getting Started","title":"Prior","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"We will choose the conjugate prior of the Bernoulli likelihood function defined above, namely the beta distribution, i.e.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"theta sim Beta(a b)","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"where a and b are the hyperparameters that encode our prior beliefs about the possible values of theta. We will assign values to the hyperparameters in a later step.   ","category":"page"},{"location":"man/getting-started/#Joint-probability","page":"Getting Started","title":"Joint probability","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"The joint probability is given by the multiplication of the likelihood and the prior, i.e.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"P(y_1N θ) = P(θ) prod_i=1^N P(y_i  θ)","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Now let's see how to specify this model using GraphPPL's package syntax.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"\n# GraphPPL.jl export `@model` macro for model specification\n# It accepts a regular Julia function and builds an FFG under the hood\n@model function coin_model(n)\n\n    # `datavar` creates data 'inputs' in our model\n    # We will pass data later on to these inputs\n    # In this example we create a sequence of inputs that accepts Float64\n    y = datavar(Float64, n)\n    \n    # We endow θ parameter of our model with some prior\n    θ ~ Beta(2.0, 7.0)\n    \n    # We assume that outcome of each coin flip is governed by the Bernoulli distribution\n    for i in 1:n\n        y[i] ~ Bernoulli(θ)\n    end\n    \n    # We return references to our data inputs and θ parameter\n    # We will use these references later on during inference step\n    return y, θ\nend\n","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"As you can see, GraphPPL offers a model specification syntax that resembles closely to the mathematical equations defined above. We use datavar function to create \"clamped\" variables that take specific values at a later date. θ ~ Beta(2.0, 7.0) expression creates random variable θ and assigns it as an output of Beta node in the corresponding FFG. ","category":"page"},{"location":"man/getting-started/#Inference-specification","page":"Getting Started","title":"Inference specification","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Once we have defined our model, the next step is to use ReactiveMP API to infer quantities of interests. To do this, we need to specify inference procedure. ReactiveMP API is flexible in terms of inference specification and is compatible both with real-time inference processing and with statis datasets. In most of the cases for static datasets, as in our example, it consists of same basic building blocks:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Return variables of interests from model specification\nSubscribe on variables of interests posterior marginal updates\nPass data to the model\nUnsubscribe ","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Here is an example of inference procedure:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"function inference(data)\n    n = length(data)\n\n    # `coin_model` function from `@model` macro returns a reference to the model object and \n    # the same output as in `return` statement in the original function specification\n    model, (y, θ) = coin_model(n)\n    \n    # Reference for future posterior marginal \n    mθ = nothing\n\n    # `getmarginal` function returns an observable of future posterior marginal updates\n    # We use `Rocket.jl` API to subscribe on this observable\n    # As soon as posterior marginal update is available we just save it in `mθ`\n    subscription = subscribe!(getmarginal(θ), (m) -> mθ = m)\n    \n    # `update!` function passes data to our data inputs\n    update!(y, data)\n    \n    # It is always a good practice to unsubscribe and to \n    # free computer resources held by the subscription\n    unsubscribe!(subscription)\n    \n    # Here we return our resulting posterior marginal\n    return mθ\nend","category":"page"},{"location":"man/getting-started/#Inference-execution","page":"Getting Started","title":"Inference execution","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Here after everything is ready we just call our inference function to get a posterior marginal distribution over θ parameter in the model.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"θestimated = inference(dataset)","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"println(\"mean: \", mean(θestimated))\nprintln(\"std:  \", std(θestimated))\nnothing #hide","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"using Plots, LaTeXStrings; theme(:default)\n\nrθ = range(0, 1, length = 1000)\n\np1 = plot(rθ, (x) -> pdf(Beta(2.0, 7.0), x), title=\"Prior\", fillalpha=0.3, fillrange = 0, label=L\"P\\:(\\theta)\", c=1,)\np2 = plot(rθ, (x) -> pdf(θestimated, x), title=\"Posterior\", fillalpha=0.3, fillrange = 0, label=L\"P\\:(\\theta|y)\", c=3)\n\nplot(p1, p2, layout = @layout([ a; b ]))","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"In our dataset we used 10 coin flips to estimate the bias of a coin. It resulted in a vague posterior distribution, however ReactiveMP scales very well for large models and factor graphs. We may use more coin flips in our dataset for better posterior distribution estimates:","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"dataset_100   = float.(rand(rng, Bernoulli(p), 100))\ndataset_1000  = float.(rand(rng, Bernoulli(p), 1000))\ndataset_10000 = float.(rand(rng, Bernoulli(p), 10000))\nnothing # hide","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"θestimated_100   = inference(dataset_100)\nθestimated_1000  = inference(dataset_1000)\nθestimated_10000 = inference(dataset_10000)\nnothing #hide","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"p3 = plot(title = \"Posterior\", legend = :topleft)\n\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_100, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:100})\", c = 4)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_1000, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:1000})\", c = 5)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_10000, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:10000})\", c = 6)\n\nplot(p1, p3, layout = @layout([ a; b ]))","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"With larger dataset our posterior marginal estimate becomes more and more accurate and represents real value of the bias of a coin.","category":"page"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"println(\"mean: \", mean(θestimated_10000))\nprintln(\"std:  \", std(θestimated_10000))\nnothing #hide","category":"page"},{"location":"man/getting-started/#Where-to-go-next?","page":"Getting Started","title":"Where to go next?","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"There are a set of demos available in ReactiveMP repository that demonstrate the more advanced features of the package. Alternatively, you can head to the Model specification which provides more detailed information of how to use ReactiveMP and GraphPPL to specify probabilistic models.","category":"page"},{"location":"#ReacitveMP.jl","page":"Introduction","title":"ReacitveMP.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Julia package for automatic Bayesian inference on a factor graph with reactive message passing.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Given a probabilistic model, ReactiveMP allows for an efficient message-passing based Bayesian inference. It uses the model structure to generate an algorithm that consists of a sequence of local computations on a Forney-style factor graph (FFG) representation of the model.","category":"page"},{"location":"#Package-Features","page":"Introduction","title":"Package Features","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"User friendly syntax for specification of probabilistic models.\nAutomatic generation of message passing algorithms including\nBelief propagation\nVariational message passing\nExpectation maximization\nSupport for hybrid models combining discrete and continuous latent variables.\nSupport for hybrid distinct message passing inference algorithm under a unified paradigm.\nEvaluation of Bethe free energy as a model performance measure.\nSchedule-free reactive message passing API.\nHigh performance.\nScalability for large models with millions of parameters and observations.\nInference procedure is differentiable.\nEasy to extend with custom nodes.","category":"page"},{"location":"#Resources","page":"Introduction","title":"Resources","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"For an introduction to message passing and FFGs, see The Factor Graph Approach to Model-Based Signal Processing by Loeliger et al. (2007).","category":"page"},{"location":"#How-to-get-started?","page":"Introduction","title":"How to get started?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Head to the Getting started section to get up and running with ForneyLab.","category":"page"},{"location":"#Table-of-Contents","page":"Introduction","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n  \"man/getting-started.md\",\n  \"man/model-specification.md\",\n  \"extra/contributing.md\"\n]\nDepth = 2","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"api/node/#node_api","page":"Node API","title":"Node API","text":"","category":"section"},{"location":"api/node/","page":"Node API","title":"Node API","text":"Deterministic\nStochastic\nisdeterministic\nisstochastic\nsdtype\nMeanField\nFullFactorisation\ncollect_factorisation\nNodeInterface\nIndexedNodeInterface\nname\ntag\nmessageout\nmessagein","category":"page"},{"location":"api/node/#ReactiveMP.Deterministic","page":"Node API","title":"ReactiveMP.Deterministic","text":"Deterministic\n\nDeterministic object used to parametrize factor node object with determinstic type of relationship between variables.\n\nSee also: Stochastic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.Stochastic","page":"Node API","title":"ReactiveMP.Stochastic","text":"Stochastic\n\nStochastic object used to parametrize factor node object with stochastic type of relationship between variables.\n\nSee also: Deterministic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.isdeterministic","page":"Node API","title":"ReactiveMP.isdeterministic","text":"isdeterministic(node)\n\nFunction used to check if factor node object is deterministic or not. Returns true or false.\n\nSee also: Deterministic, Stochastic, isstochastic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.isstochastic","page":"Node API","title":"ReactiveMP.isstochastic","text":"isstochastic(node)\n\nFunction used to check if factor node object is stochastic or not. Returns true or false.\n\nSee also: Deterministic, Stochastic, isdeterministic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.sdtype","page":"Node API","title":"ReactiveMP.sdtype","text":"sdtype(object)\n\nReturns either Deterministic or Stochastic for a given object (if defined).\n\nSee also: Deterministic, Stochastic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.MeanField","page":"Node API","title":"ReactiveMP.MeanField","text":"MeanField\n\nGeneric factorisation constraint used to specify a mean-field factorisation for recognition distribution q.\n\nSee also: FullFactorisation\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.FullFactorisation","page":"Node API","title":"ReactiveMP.FullFactorisation","text":"FullFactorisation\n\nGeneric factorisation constraint used to specify a full factorisation for recognition distribution q.\n\nSee also: MeanField\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.collect_factorisation","page":"Node API","title":"ReactiveMP.collect_factorisation","text":"collect_factorisation(nodetype, factorisation)\n\nThis function converts given factorisation to a correct internal factorisation representation for a given node. \n\nSee also: MeanField, FullFactorisation\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.NodeInterface","page":"Node API","title":"ReactiveMP.NodeInterface","text":"NodeInterface\n\nNodeInterface object represents a single node-variable connection.\n\nSee also: name, tag, messageout, messagein\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.IndexedNodeInterface","page":"Node API","title":"ReactiveMP.IndexedNodeInterface","text":"IndexedNodeInterface\n\nIndexedNodeInterface object represents a repetative node-variable connection.  Used in cases when node may connect different number of random variables with the same name, e.g. means and precisions of Gaussian Mixture node.\n\nSee also: name, tag, messageout, messagein\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.name","page":"Node API","title":"ReactiveMP.name","text":"name(interface)\n\nReturns a name of the interface.\n\nSee also: NodeInterface, tag\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.tag","page":"Node API","title":"ReactiveMP.tag","text":"tag(interface)\n\nReturns a tag of the interface in the form of Val{ name(interface) }.  The major difference between tag and name is that it is possible to dispath on interface's tag in message computation rule.\n\nSee also: NodeInterface, name\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.messageout","page":"Node API","title":"ReactiveMP.messageout","text":"messageout(interface)\n\nReturns an outbound messages stream from the given interface.\n\nSee also: NodeInterface, messagein\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.messagein","page":"Node API","title":"ReactiveMP.messagein","text":"messagein(interface)\n\nReturns an inbound messages stream from the given interface.\n\nSee also: NodeInterface, messageout\n\n\n\n\n\n","category":"function"},{"location":"api/node/","page":"Node API","title":"Node API","text":"Internal API","category":"page"},{"location":"api/node/","page":"Node API","title":"Node API","text":"ReactiveMP.connectvariable!\nReactiveMP.connectedvar\nReactiveMP.connectedvarindex\nReactiveMP.get_pipeline_stages\nReactiveMP.add_pipeline_stage!\nReactiveMP.FactorNodeLocalMarginal\nReactiveMP.FactorNodeLocalMarginals","category":"page"},{"location":"api/node/#ReactiveMP.connectvariable!","page":"Node API","title":"ReactiveMP.connectvariable!","text":"connectvariable!(interface, variable, index)\n\nConnects a variable with the interface and given index. Index is used to distinguish this connection from others in case if variable is connected to multiple interfaces.\n\nSee also: NodeInterface, connectedvar, connectedvarindex\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.connectedvar","page":"Node API","title":"ReactiveMP.connectedvar","text":"connectedvar(interface)\n\nReturns connected variable for the interface.\n\nSee also: NodeInterface, connectvariable!, connectedvarindex\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.connectedvarindex","page":"Node API","title":"ReactiveMP.connectedvarindex","text":"connectedvarindex(interface)\n\nReturns an index of connected variable for the interface.\n\nSee also: NodeInterface, connectvariable!, connectedvar\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.get_pipeline_stages","page":"Node API","title":"ReactiveMP.get_pipeline_stages","text":"get_pipeline_stages(interface)\n\nReturns an instance of pipeline stages of connected variable for the given interface\n\nSee also: NodeInterface, connectvariable!, connectedvar, add_inbound_pipeline_stage!\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.FactorNodeLocalMarginal","page":"Node API","title":"ReactiveMP.FactorNodeLocalMarginal","text":"FactorNodeLocalMarginal\n\nThis object represents local marginals for some specific factor node.  Local marginal can be joint in case of structured factorisation.  Local to factor node marginal also can be shared with a corresponding marginal of some random variable.\n\nSee also: FactorNodeLocalMarginals\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.FactorNodeLocalMarginals","page":"Node API","title":"ReactiveMP.FactorNodeLocalMarginals","text":"FactorNodeLocalMarginals\n\nThis object acts as an iterable and indexable proxy for local marginals for some node. \n\n\n\n\n\n","category":"type"},{"location":"extra/contributing/#Contribution-guidelines","page":"Contributing","title":"Contribution guidelines","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We welcome all possible contributors. This page details the some of the guidelines that should be followed when contributing to this package.","category":"page"},{"location":"extra/contributing/#Reporting-bugs","page":"Contributing","title":"Reporting bugs","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We track bugs using GitHub issues. We encourage you to write complete, specific, reproducible bug reports. Mention the versions of Julia and ReactiveMP for which you observe unexpected behavior. Please provide a concise description of the problem and complement it with code snippets, test cases, screenshots, tracebacks or any other information that you consider relevant. This will help us to replicate the problem and narrow the search space for solutions.","category":"page"},{"location":"extra/contributing/#Suggesting-features","page":"Contributing","title":"Suggesting features","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We welcome new feature proposals. However, before submitting a feature request, consider a few things:","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"Does the feature require changes in the core ReactiveMP.jl code? If it doesn't (for example, you would like to add a factor node for a particular application), you can add local extensions in your script/notebook or consider making a separate repository for your extensions.\nIf you would like to add an implementation of a feature that changes a lot in the core ReactiveMP.jl code, please open an issue on GitHub and describe your proposal first. This will allow us to discuss your proposal with you before you invest your time in implementing something that may be difficult to merge later on.","category":"page"},{"location":"extra/contributing/#Contributing-code","page":"Contributing","title":"Contributing code","text":"","category":"section"},{"location":"extra/contributing/#Installing-ReactiveMP","page":"Contributing","title":"Installing ReactiveMP","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We suggest that you use the dev command from the new Julia package manager to install ReactiveMP.jl for development purposes. To work on your fork of ReactiveMP.jl, use your fork's URL address in the dev command, for example:","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"] dev git@github.com:your_username/ReactiveMP.jl.git","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"The dev command clones ReactiveMP.jl to ~/.julia/dev/ReactiveMP. All local changes to ReactiveMP code will be reflected in imported code.","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"note: Note\nIt is also might be useful to install Revise.jl package as it allows you to modify code and use the changes without restarting Julia.","category":"page"},{"location":"extra/contributing/#Committing-code","page":"Contributing","title":"Committing code","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We use the standard GitHub Flow workflow where all contributions are added through pull requests. In order to contribute, first fork the repository, then commit your contributions to your fork, and then create a pull request on the master branch of the ReactiveMP.jl repository.","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"Before opening a pull request, please make sure that all tests pass without failing! All demos (can be found in /demo/ directory) and benchmarks (can be found in /benchmark/ directory) have to run without errors as well.","category":"page"},{"location":"extra/contributing/#Style-conventions","page":"Contributing","title":"Style conventions","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We use default Julia style guide. We list here a few important points and our modifications to the Julia style guide:","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"Use 4 spaces for indentation\nType names use UpperCamelCase. For example: AbstractFactorNode, RandomVariable, etc..\nFunction names are lowercase with underscores, when necessary. For example: activate!, randomvar, as_variable, etc..\nVariable names and function arguments use snake_case\nThe name of a method that modifies its argument(s) must end in !","category":"page"},{"location":"extra/contributing/#Unit-tests","page":"Contributing","title":"Unit tests","text":"","category":"section"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"We use the test-driven development (TDD) methodology for ReactiveMP.jl development. The test coverage should be as complete as possible. Please make sure that you write tests for each piece of code that you want to add.","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"All unit tests are located in the /test/ directory. The /test/ directory follows the structure of the /src/ directory. Each test file should have following filename format: test_*.jl. Some tests are also present in jldoctest docs annotations directly in the source code. See Julia's documentation about doctests.","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"The tests can be evaluated by running following command in the Julia REPL:","category":"page"},{"location":"extra/contributing/","page":"Contributing","title":"Contributing","text":"] test ReactiveMP","category":"page"}]
}
