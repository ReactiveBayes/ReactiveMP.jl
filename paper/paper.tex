
% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}

\begin{document}

\input{header}

\maketitle

\begin{abstract}

ReactiveMP.jl is a native Julia implementation of reactive message passing-based Bayesian inference in probabilistic graphical models. 
The package supports a large range of standard probabilistic models and can be extended to custom novel nodes and message update rules. 
In contrast to non-reactive (imperatively coded) Bayesian inference packages, ReactiveMP.jl scales easily to support inference on a standard laptop 
for large models with tens of thousands of variables and millions of nodes.

\end{abstract}

\section{Background}

Bayesian inference is one of the key computational mechanisms that underlies probabilistic model-based machine learning applications. 
Unfortunately, for many practical models, Bayesian inference requires evaluating high-dimensional integrals that have no analytical solution. 
As a result, Probabilistic Programming (PP) tools for Automated Approximate Bayesian Inference (AABI) have become popular, e.g., \textit{Turing.jl} \cite{ge2018t}, 
\textit{ForneyLab.jl} \cite{ForneyLab.jl-2019} and others. These tools help researchers to specify probabilistic models in a high-level domain-specific language and 
run AABI algorithms with minimal additional overhead. 

\section{Message Passing}

An important issue in the development of PP frameworks is scalability of AABI algorithms for large models and large data sets. 
One solution approach concerns message passing-based inference in factor graphs. In this framework, relationships between model variables are represented by a graph of sparsely connected nodes, 
and inference proceeds efficiently by a sequence of nodes sending probabilistic messages to neighboring nodes. While the optimal message passing schedule is data-dependent, 
all existing factor graph frameworks (e.g., Infer.Net, ForneyLab.jl) use preset message sequence schedules. The potential benefits of massively parallel and asynchronous r
eactive message passing in a factor graph include scaling to large inference tasks, much smaller processing latency and processing of data samples that arrive at irregular time intervals.

\section{Reactive Message Passing}

We present \textbf{ReactiveMP.jl} package, which is a native Julia \cite{bezanson2017julia} package for automated \textit{reactive} message passing-based (both exact and approximate) Bayesian inference and corresponding
Constrained Bethe Free Energy (CFBE) functional optimisation \cite{senoz_local_constraint_2021}. ReactiveMP.jl is based on a reactive programming approach, does not enforce any particular message-passing schedule, 
supports real-time data inference and scales comfortably to inference tasks on factor graphs with tens of thousands of variables and millions of nodes.

The package comes with a collection of standard probabilistic models, including linear Gaussian state-space models, hidden Markov models, auto-regressive models and mixture models. 
Moreover, ReactiveMP.jl API supports various processing modes such as offline learning, filtering of infinite data streams and protocols for handling missing data.

ReactiveMP.jl provides an easy way to add new models, node functions and analytical message update rules to the existing platform. 
The resulting inference procedures are differentiable with \textit{ForwardDiff.jl} \cite{RevelsLubinPapamarkou2016}. As for computation time and memory usage, 
specifically for conjugate models, ReactiveMP.jl outperforms Turing.jl and ForneyLab.jl significantly by orders of magnitude. Performance benchmarks are available at the GitHub repository.

\section{Acknowledgements}

We acknowledge contributions from Albert Podusenko, Ismail Senoz, and Bart van Erp, and support from the whole BIASlab group during this project.

\input{bib.tex}

\end{document}

% Inspired by the International Journal of Computer Applications template
