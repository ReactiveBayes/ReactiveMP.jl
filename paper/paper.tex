
% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}

\begin{document}

\input{header}

\maketitle

\begin{abstract}

ReactiveMP.jl is a native Julia implementation of reactive message passing-based Bayesian inference in probabilistic graphical models with Factor Graphs. 
The package does Constrained Bethe Free Energy minimisation and supports both exact and variational Bayesian inference, provides a convenient syntax for model specification and allows for extra factorisation and form constraints specification of the
variational family of distributions. In addition, ReactiveMP.jl includes a large range of standard probabilistic models and can easily be extended to custom novel nodes and message update rules. 
In contrast to non-reactive (imperatively coded) Bayesian inference packages, ReactiveMP.jl scales easily to support inference on a standard laptop 
for large conjugate models with tens of thousands of variables and millions of nodes. 

\end{abstract}

\section{Background}

Bayesian inference is one of the key computational mechanisms that underlies probabilistic model-based machine learning applications. 
Unfortunately, for many practical models, Bayesian inference requires evaluating high-dimensional integrals that have no analytical solution. 
As a result, Probabilistic Programming (PP) tools for Automated Approximate Bayesian Inference (AABI) become popular, e.g., \textit{Turing.jl} \cite{ge2018t}, 
\textit{ForneyLab.jl} \cite{ForneyLab.jl-2019} and others. These tools help researchers to specify probabilistic models in a high-level domain-specific language and 
run AABI algorithms with minimal additional overhead. 

\section{Message Passing}

An important issue in the development of PP frameworks is scalability of AABI algorithms for large models and large data sets. 
One solution approach concerns message passing-based inference in factor graphs. In this framework, relationships between model variables are represented by a graph of sparsely connected nodes, 
and inference proceeds efficiently by a sequence of nodes sending probabilistic messages to neighboring nodes. While the optimal message passing schedule is data-dependent, as far as the authors are aware
all existing factor graph frameworks (e.g., Infer.Net \cite{InferNET18}, ForneyLab.jl) use preset message sequence schedules. In our work we exploit the reactive programming approach in the context of message passing 
based Bayesian inference. The potential benefits of reactive message passing in a factor graph include scaling to large inference tasks, much smaller processing latency and processing of data samples that arrive at irregular time intervals.

\section{Reactive Message Passing}

We present the \textbf{ReactiveMP.jl} package, which is a native Julia \cite{bezanson2017julia} package for automated \textit{reactive} message passing-based Bayesian inference and corresponding
Constrained Bethe Free Energy (CFBE) functional optimisation \cite{senoz_local_constraint_2021}. ReactiveMP.jl is based on a reactive programming approach, does not enforce any particular message-passing schedule, and supports real-time data inference. 
In our experiments this new implementation scales comfortably to inference tasks on factor graphs with hundreds of thousands of variables and millions of nodes.

The package comes with a collection of standard probabilistic models, including linear Gaussian state-space models, hidden Markov models, auto-regressive models and mixture models. 
Moreover, ReactiveMP.jl's API supports various processing modes such as offline learning, filtering of infinite data streams and protocols for handling missing data.

The current implementation of ReactiveMP.jl does not run inference for all models supported by more general-purpose PPLs and is limited to conjugate state-space models, but it is customizable and provides an easy way to add new models, node functions and analytical message update rules to the existing platform. 
As a result, a user can extend built-in functionality with custom nodes to run automated inference in novel probabilistic models.
The resulting inference procedures are differentiable with \textit{ForwardDiff.jl} \cite{RevelsLubinPapamarkou2016} and support different types of floating point numbers, e.g., the built-in BigFloat Julia type.
As for computation time and memory usage, for supported conjugate models, ReactiveMP.jl outperforms Turing.jl and ForneyLab.jl significantly by orders of magnitude. Performance benchmarks are available at the GitHub repository.

\section{Conclusions}

Automating scalable Bayesian inference is a key factor in the quest to apply Bayesian machine learning to useful applications. We developed ReactiveMP.jl as 
a package that enables developers to build large novel probabilistic models and automate scalable inference in those models by reactive message passing in a factor graph. 

\section{Acknowledgements}

We acknowledge contributions from Albert Podusenko, Ismail Senoz, and Bart van Erp, and support from the whole BIASlab group during this project.

\input{bib.tex}

\end{document}

% Inspired by the International Journal of Computer Applications template
